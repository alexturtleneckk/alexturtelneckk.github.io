---
layout: post
title:  "Hand On Machine Learning QnA"
author: alex
date : 2023-11-28
category : ML
tags :  
image: assets/images/231128/handsonml.jpeg
---

# 문제 모음

### 1장 한눈에 보는 머신러닝

1. `머신러닝`을 어떻게 정의할 수 있나요?

        명시적인 프로그래밍 없이 컴퓨터가 데이터로부터 학습하는 능력을 갖추게 하는 것.

        학습이란 어떤 작업에서 주어진 ‘성능 지표’가 더 나아지는 것을 의미한다.
        
2. 머신러닝이 도움을 줄 수 있는 문제 유형 네가지를 말해보세요.
        
        1)많은 규칙
        
        3)복잡한 문제
        
        4)대량의 데이터에서 통찰 
        
        2)변화하는 환경에 적응하는 시스템 
        
3. 레이블된 훈련세트란 무엇인가요?
        
        ‘각 샘플’에 ‘원하는 정답’을 담고 있는 훈련 세트
        
4. 가장 널리 사용되는 지도 학습 작업 두가지는 무엇인가요?
        
        회귀와 분류 
        
5. 보편적인 비지도 학습 작업 네가지는 무엇인가요?
        
        군집, 시각화, 차원 축소, 연관 규칙 학습
        
6. 사전 정보가 없는 여러 지형에서 로봇을 걸어가게 하려면 어떤 종류의 머신러닝 알고리즘을 사용할 수 있나요?
        
        `강화학습`. 학습하는 시스템을`에이전트`라고 부르며 환경을 관찰해서 `행동`을 실행하고 그 결과로 `보상` 또는 `벌점`을 받고 시간이 지나면 가장 큰 보상을 얻기 위해 `정책`이라고 부르는 최상의 전략을 스스로 학습
        
![%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2023-05-03_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_7 49 56](https://github.com/alexturtleneckk/alexturtleneckk/assets/107594866/bc8324b6-35fe-40c2-bb50-f017b0e70b56)
        
7. 고객을 여러 그룹으로 분할하려면 어떤 알고리즘을 사용해야 하나요?
        
        어떤 그룹이 있어야 할지 안다면 지도 학습인 분류 알고지즘 사용
        
        그룹을 어떻게 정의할지 모른다면 비슷한 고객끼리 군집으로 나누기 위해 비지도 학습인 군집 알고리즘을 사용. 
        
8. 스팸 감지의 문제는 지도학습과 비지도 학습 중 어떤 문제로 볼 수 있나요?
        
        지도 학습. 알고리즘에 많은 이메일과 이에 상응하는 스팸인지 스팸이 아닌지 적힌 레이블이 제공
        
9. 온라인 학습 시스템이 무엇인가요?
        
        데이터를 순차적으로 한 개씩 또는 `미니배치` 단위로 주입하여 시스템을 훈련 
        
        - 시스템이 빠르게 변해야 하거나
        - 데이터 양이 많거나 **`외부 메모리 학습`**
        - 자원이 제한된 시스템
        
        → 점진적으로 학습할 수 있는 알고리즘 사용
        
        ex) 온라인 내에서 사람들이 결제할 때마다 학습 
        
        ex) 화성 탐사 로봇  
        
10. 외부 메모리 학습이 무엇인가요?
        
        컴퓨터의 주 메모리에 들어갈 수 없는 대용량의 데이터를 다룰 수 있습니다. 외부 메모리 학습 알고리즘은 데이터를 미니배치로 나누고 온라인 학습 기법을 사용해 학습
        
11. 예측을 하기 위해 유사도측정에 의존하는 학습 알고리즘은 무엇인가요?
        
        사례 기반 학습 시스템은 훈련 데이터를 기억하는 학습. 새로운 샘플이 주어지면 유사도 측정을 사용해 학습된 샘플 중에서 가장 비슷한 것을 찾아 예측으로 사용 
        
12. 모델 파라미터와 학습 알고리즘의 파라미터 사이에는 어떤 차이가 있나요?
        
        모델은 하나 이상의 파라미터를 사용해 새로운 샘플이 주어지면 무엇을 예측할지 결정합니다. 그 예시로 선형 모델의 기울기
        
        학습 알고리즘은 모델이 새로운 샘플에 잘 일반화되도록 이런 파라미터들의 최적값을 찾는다. 하이퍼파라미터는 모델이 아니라 이런 학습 알고리즘 자체의 파라미터입니다. 그 예시로 적용할 규제의 정도
        
13. 모델 기반 알고리즘이 찾는 것은 무엇인가요? 성공을 위해 이 알고리즘이 사용하는 가장 일반적인 전략은 무엇인가요? 예측은 어떻게 만드나요?
        
        모델 기반 학습 알고리즘은 새로운 샘플에 잘 일반화되기 위한 모델 파라미터의 최적값을 찾습니다. 일반적으로 훈련 데이터에서 시스템의 예측이 얼마나 나쁜지 측정하고 모델에 규제가 있다면 모델 복잡도에 대한 페널티를 더한 비용 함수를 최소함으로써 시스템을 훈련. 예측을 만들려면 학습 알고리즘이 찾은 파라미터를 사용하는 모델의 예측함수에 새로운 샘플의 특성을 주입. 
        
14. 머신러닝의 주요 도전과제는 무엇인가요?
        
        부족한 데이터, 낮은 데이터 품질, 대표성 없는 데이터, 무의미한 특성, 과소적합 모델, 과대적합 모델
        
15. 모델이 훈련 데이터에서의 성능은 좋지만 새로운 샘플에서의 일반화 성능이 나쁘다면 어떤 문제가 있는 건가요? 가능한 해결책 세가지는 무엇인가요?
        
        훈련 데이터에 과대적합되었을 가능성이 높다. 
        
        1) 더 많은 데이터 수집
        
        2) 모델을 단순화 → 간단한 알고리즘 선택, 특성이나 파라미터 수 줄이기, 모델에 규제 추가 
        
        3) 전처리를 통해 련 데이터 잡음 감소
        
16. 테스트 세트가 무엇이고 왜 사용해야 하나요?
        
        실전에 배치되기 전에 모델이 새로운 샘플에 대해 만들 일반화 오차를 추정하기 위해 사용 
        
17. 검증 세트의 목적은 무엇인가요?
        
        모델을 비교하는데 사용. 이를 사용해 가장 좋은 모델을 고르고 하이퍼파라미터를 튜닝
        
18. 훈련-개발 세트가 무엇인가요? 언제 필요하고 어떻게 사용해야 하나요?
        
        검증, 테스트 세트에 사용되는 데이터와 훈련 세트 사이에 데이터 불일치 위험이 있을 때 사용. 훈련 세트의 일부에서 모델을 훈련하고 훈련-개발 세트와 검증 세트에서 평가. 모델이 훈련 세트에서 잘 동작하지만 훈련-개발 세트에서 나쁜 성능을 낸다면 훈련 세트에 과대적합되었을 가능성이 높다. 훈련 세트와 훈련-개발 세트 양쪽에서 모두 잘 동작하지만 검증 세트에서 성능이 나쁘다면 훈련 데이터와 검증, 테스트 데이터 사이에 데이터 불일치가 있을 가능성이 높다. 검증 ,테스트 데이터에 더 가깝게 되도록 훈련 데이터를 개선
        
19. 테스트 세트를 사용해 하이퍼 파라미터를 튜닝하면 어떤 문제가 생기나요?
        
        테스트 세트에 과대적합될 위험이 있고 일반화 오차를 낙관적으로 측정. 모델을 출시하면 기대한 것보다 나쁜 성능을 낼것 


### 4장 나쁜 데이터와 나쁜 알고리즘

1. 수백만 개의 특성을 가진 훈련 데이트 세트에서는 어떤 선형회귀 알고리즘을 사용할 수 있을까요?
        
        확률적 경사 하강법이나 미니배치 경사 하강법 사용 가능. 
        
        훈련 세트가 메모리 크기에 맞으면 배치 경사 하강법도 가능.
        
        하지만 정규방정식이나 SVD 방법은 계산 복잡도가 특성 개수에 따라 매우 빠르게 증가하기 때문에 사용 X
        
2. 훈련 세트에 있는 특성들이 각기 아주 다른 스케일을 가지고 있습니다. 이런 데이터에 잘 작동하지 않는 알고리즘은 무엇일까요? 그 이유는 무엇일까요? 이 문제를 어떻게 해결할 수 있을까요?
        
        이 상황에서는 비용 함수는 길쭉한 타원 모양의 그릇 형태가 되어서 경사하강법 알고리즘이 수렴하는데 오랜 시간이 걸림. 이를 해결하기 위해 모델을 훈련하기 전 데이터의 스케일 조절. 
        
        정규방정식이나 SVD방법은 스케일 조정 없이도 잘 작동. 
        
        규제가 있는 모델은 특성의 스케일이 다르면 지역 최적값에 수렴할 가능성이 있다. 규제는 가중치가 커지지 못하게 제약을 가하므로 특성값이 작으면 큰 값을 가진 특성에 비해 무시되는 경향이 있다 
        
3. 경사 하강법으로 로지스틱회귀 모델을 훈련시킬 때,  지역 최솟값에 갇힐 가능성이 있을까요?
        
        로지스틱 회귀 모델의 비용 함수는 볼록 함수이므로 경사하강법이 훈련될 때 지역 최솟값에 갇힐 가능성이 없다. 
        
4. 충분히 오랫동안 실행하면 모든 경사 하강법 알고리즘이 같은 모델을 만들어낼까요?
        
        아니요. 조금씩 다른 모델을 만든다.
        
        학습률을 점진적으로 감소시키지 않으면 SGD와 미니배치 GD는 진정한 최적점에 수렴하지 못하고 전역 최적점 주변을 맴돌게 됨. 
        
5. 배치 경사 하강법을 사용하고 에포크마다 검증 오차를 그래프로 나타내봤습니다. 검증 오차가 일정하게 상승되고 있다면 어떤 일이 일어나고 있는 걸까요? 이 문제를 어떻게 해결 할 수 있나요?
        
        학습률이 너무 높고 알고리즘이 발산해서 일 수 있다.
        
        훈련 에러도 올라간다면 이 문제가 확실하고 학습률을 낮추어야 한다.
        
        그러나 훈련 에러가 올라가지 않는다면 모델이 훈련 세트에 과대적합되어 있는 것이므로 훈련을 멈추어야 함
        
6. 검증 오차가 상승하면 미니 배치 경사 하강법을 즉시 중단하는 것이 좋은 방법인가요?
        
        무작위성 때문에 확률적 경사 하강법이나 미니배치 경사 하강법 모두 매 훈련 반복마다 학습의 진전을 보장하지 못함. 검증 에러가 상승 될 때 훈련을 즉시 멈춘다면 최적점에 도달하기 전에 너무 일찍 멈추게 될지 모른다. 더 나은 방법으로는 정기적으로 모델을 저장하고 오랫동안 진전이 없을 때, 저장된 것 중 가장 좋은 모델로 복원. 
        
7. 어떤 경사 하강법 알고리즘이 가장 빠르게 최적 솔루션의 주변에 도달할까요? 실제로 수렴하는 것은 어떤 것인가요? 다른 방법들도 수렴하게 만들 수 있나요?
        
        
8. 다항 회귀를 사용했을 때, 학습 곡선을 보니 훈련 오차와 검증 오차 사이에 간격이 큽니다. 무슨 일이 생긴 걸까요? 이 문제를 해결하는 세가지 방법은 무엇인가요?
9. 릿지 회귀를 사용했을 때, 훈련 오차와 검증 오차가거의 비슷하고 둘 다 높았습니다. 이 모델에는 높은 편향이 문제인가요, 아니면 높은 분산이 문제인가요? 규제 하이퍼파라미터 a를 증가시켜야 할까요? 아니면 줄여야 할까요?
10. 다음과 같이 사용해야 하는 이유는?
        - 평범한 선형 회귀(즉, 아무런 규제가 없는 모델) 대신 릿지 회귀
        - 릿지회귀 대신 라쏘 회귀
        - 라쏘 회귀 대신 일라스틱 넷
11. 사진을 낮과 밤, 실내와 실외로 분류하려합니다. 두개의 로지스틱 회귀 분류기를 만들어야할까요, 아니면 하나의 소프트맥스 회귀 분류기를 만들어야 할까요?
### 5장 서포트 벡터 머신
1. `서포트 벡터 머신`의 근본 아이디어는?
        
        두 클래스를 구분하는 ‘결정 경계’와 ‘샘플’ 사이의 마진을 가능한 크게 하는 것이 목적. 
        
        소프트 마진 분류를 수행할 때는 SVM이 두 클래스를 완벽하게 나누는 것과 가장 넓은 도로를 만드는 것 사이에 절충안을 찾는다. 
        
2. `서포트 벡터`가 무엇인가?
        
        서포트 벡터는 SVM 훈련 후에 경계를 포함해 도로에 놓인 샘플이고 서포트 벡터에 의해 1)결정 경계가 결정된다. 서포트 벡터가 아닌 어떤 샘플도 결정경계에 영향을 주지 못하고 2) 예측을 계산할 때에도 전체 훈련 세트가 아니라 서포트 벡터만 관여한다.
        
3. SVM을 사용할 때 입력값의 스케일 왜 중요한가?
        
        SVM은 클래스 사이의 가능한 큰 도로를 내는 것이 목적이므로 스케일이 다르게 되면 작은 특성은 무시하는 경향이 있다
        
### 6장 결정 트리
1. 백만 개의 샘플을 가진 훈련 세트에서 규제 없이 훈련시킨 결정 트리의 깊이는?
        
        균형이 잘 잡힌 이진 트리는 가지가 2개이므로 깊이는 $log2(m)$과 같다. 따라서 $log2(10^6)$=20이 된다.
        
2. 한 노드의 지니 불순도가 보통 그 부모 노드보다 작을까요, 아니면 클까요?
        
        일반적으로 한 노드의 지니 불순도는 일반적으로 부모의 불순도보다 낮습니다. 이는 ‘지니 불순도의 가중치의 합’이 최소화되는 방향으로 각 노드를 분할하는 ‘CART 훈련 알고리즘의 비용 함수’ 때문입니다. 
        
        그러나 다른 자식 노드의 지니 불순도 감소량이 어떤 노드의 불순도 증가량보다 큰 경우라면 부모의 불순도보다 큰 노드가 생길 수 있습니다. 
        
3. 결정 트리가 훈련 세트에 과대적합되었다면 max depth를 줄이는 것이 좋을까요?
        
        네. 줄여서 규제를 높이는 것이 좋습니다.
        
4. 결정 트리가 훈련 세트에 과소적합되었다된 입력 특성의 스케일을 조정하는 것이 좋을까요?
        
        결정 트리는 훈련 데이터의 스케일이나 원점에 맞추어져 있는지 상관하지 않는 것이 장점입니다. 그러므로 스케일을 조정하는 것은 시간 낭비입니다. 
        
5. 백만 개의 샘플을 가진 훈련 세트에 결정 트리를 훈련시키는데 한 시간이 걸렸다면, 천만개의 샘플을가진 훈련세트에 결정 트리를 훈련시키는 데는 대략 얼마나 걸릴까요?
        
        결정 트리의 계산 복잡도는  $O(n*mlog(m))$ n:특성수, m : 샘플 수
        
6. 십만 개의 훈련 샘플을 가진 훈련 세트가 있다면 presort=True로 지정하는 것이 훈련 속도를 높일까요?
        
        퀵정렬을 통해 sorting 하는데 시간 복잡도가 O(nlog(n))이므로 매우 느려진다. 샘플이 수 천개일 때만 적용. 
        
### 7장 앙상블 학습과 랜덤 포레스트
1. 정확히 같은 훈련 데이터로 다섯 개의 다른 모델을 훈련시켜서 모두 95% 정확도를 얻었다면 이 모델들을 연결하여 더 좋은 결과를 얻을 수 있을까요?가능하다면 어떻게 해야 할까요? 그렇지 않다면 왜?
        
        직접 투표와 간접 투표 분류기 사이의 차이점은?
        
        네. `Ensemble`을 통해 더 좋은 결과를 얻을 수 있습니다. 서로 다른 모델이므로 voting과 boosting 방법을 쓸 수 있습니다. `Voting` 중 
        
        `Hard voting`은 ‘전체 훈련 세트 하나’에 대해 ‘여러 개의 분류기’를 훈련시킨 후 각 분류기의 예측을 모아서 가장 많이 선택된 클래스로 예측하는 방법으로, 이렇게 다수결 투표로 정해지는 분류기를 말합니다. 
        
        `Soft voting`은 모든 분류기가 ‘클래스의 확률’을 예측할 수 있으면 개별 분류기의 예측을 평균내어 확률이 가장 높은 클래스를 예측합니다.
        
        `Boosting`은 약한 학습기를 여러 개 연결하여 강한 학습기를 만드는 앙상블 방법으로 
        
        `AdaBoost`은 이전 모델이 ‘Underfitting했던 training data’의 ‘가중치’를 더 높이며 새로운 모델 생성
        
        `Gradient boost`도 동일한 방식이지만 가중치 대신 ‘잔여 오차’를 새로운 예측기에 학습
        
2. 배깅 앙상블의 훈련을 여러 대의 서버에 분산시켜 속도 증가 가능? 페이스팅 앙상블, 부스팅 앙상블, 랜덤 포레스트, 스태킹 앙상블의 경우는 어떨까요?
        
        배깅, 페이스팅, 랜덤 포레스트는 각 예측기가 독립적이므로 여러 대의 서버에 분산하여 훈련 속도 증가
        
        부스팅 앙상블의 예측기는 이전 예측기를 기반으로 만들어지므로 훈련이 순차적이어야 해서 증가 X
        
        스태킹은 한 층의 모든 예측기가 각각 독립적이므로 여러 대의 서버에서 병렬로 훈련될 수 있으나 한 층에 있는 예측기들은 이전 층의 예측기들이 훈련된 후에 훈련 가능
        
        `Bagging` ’전체 훈련 세트의 서브셋’을 무작위로 구성하여 ‘하나의 분류기’를 각기 다르게 학습시키는 방법이다. 훈련 세트에서 중복을 허용하는 샘플링하는 방식이다. `Pasting`훈련 세트에서 중복을 허용하지 않고 샘플링하는 방식이다.
        
        `Stacking` 앙상블에 속한 모든 예측기의 예측을 취합하는 간단한 함수(Hard Voting 등)을 사용하는 대신, 취합하는 모델 자체를 훈련 시키고자 하는 방법이다.  예측기는 각각 다른 값을 예측하고, 마지막 예측기(블렌더)가 이 예측을 입력으로 받아 최종 예측을 만든다.
        
3. ooh 평가의 장점은?
        
        `ooh(out of bag sample)` 배깅에서 선택되지 않은 샘플로  <valid set로 대신 사용> 할 수 있습니다. 이는 추가적인 검증 세트가 없어도 편향되지 않게 앙상블을 평가하도록 도와주어 훈련에 더 많은 샘플을 사용할 수 있어서 앙상블의 성능이 조금 더 향상 될 것입니다. 
        
4. 에이다부스트 앙상블이 훈련 데이터에 과소적합되었다면 어떤 매개변수를 어떻게 바꾸어야 할까요?
        
        1) 예측기 수 증가
        
        2) 규제 감소
        
        3) 학습률 증가 
        
### 8장 차원축소
1. 차원 축소 목적과 단점?
        
        [ 목적 ]
        
        1) 잡음과 중복된 특성을 삭제할 수 있어 훈련 알고리즘의 성능을 높인다
        
        2) 데이터를 시각화하고 가장 중요한 특성에 대한 통찰을 얻기 위해
        
        3) 메모리 공간을 절약하기 위해
        
        [ 단점 ]
        
        1) 일부 정보를 잃어버려 훈련 알고리즘의 성능 감소 가능
        
        2) 계산 비용이 높다
        
        3) 머신러닝 파이프라인의 복잡도를 증가시킨다
        
        4) 변환된 데이터를 이해하기 어려운 경우가 많다
        
2. 차원의 저주란?
        
        고차원 공간이기 때문에 일어나는 문제로, 고차원 벡터는 매우 희소해서 많은 양의 데이터가 있지 않으면 데이터에 있는 패턴을 잡아내기 어려워 과대적합의 위험이 큰 것을 이야기합니다.
        
3. 데이터셋의 차원을 축소시키고 이 작업을 원복 할 수 있나요?
        
        PCA 같은 알고리즘은 일부 정보가 차원 축소 과정에서 이를 완벽하게 되돌리는 것은 불가능합니다. 
        
        T-SNE 같은 알고리즘은 비교적 원본과 비슷한 데이터셋을 재구성할 수 있는 역변환 방법을 가지고 있다.
        
4. 매우 비선형적인 데이터셋의 차원을 축소하는데 PCA를 사용할 수 있는가?
        
        PCA는 불필요한 차원을 제거할 수 있기 때문에 매우 비선형적이더라도 사용할 수 있다.
        
        그러나 스위스 롤 데이터셋처럼 불필요한 차원이 없다면 PCA 차원 축소는 너무 많은 정보를 잃게 만든다.
        
5. 설명된 분산이 95%인 PCA를 1000개의 차원을 가진 데이터셋에 적용한다면 차원 개수는?
        
        데이터셋에 따라 다르다. 
        
        거의 일렬로 늘어선 데이터 포인트로 구성된 데이터셋은 단 하나의 차원으로 줄일 수 있다.
        
        완전히 무작위로 1000개의 차원에 걸쳐 흩어져 있는 데이터셋은 거의 950개의 차원이 필요하다.
        
6. PCA 종류
        
        
        |  | 유용한 곳 | 단점 |
        | --- | --- | --- |
        | 기본   | 우선적 사용, 데이터셋 크기가 메모리에 맞을 때 가능 |  |
        | 점진적 | 대용량 데이터셋, 실시간으로 PCA 적용해야 하는 온라인 작업 | 느리다 |
        | 랜덤 | 차원을 크게 축소, 빠르다 |  |
        | 커널 | 비선형 데이터셋 |  |

### 9장 비지도 학습
1. 군집을 어떻게 정의? 몇 개의 군집 알고리즘을 말해보라
        
        군집은 유사한 샘플을 모으는 비지도 작업.
        
        유사도 개념은 주어진 문제에 따라 다른데, 어떤 경우에는 가까이 있는 두 샘플을 비슷하다고 할 수 있지만 다른 경우에는 조밀하게 모여 있는 그룹에 같이 속해 있는 한 멀리 떨어진 샘플도 비슷할 수 있다.
        
        k-평균, DBSCAN
        
2. 군집 알고리즘 어디 사용?
        
        고객 분류, 추천 시스템, 검색 엔진, 이상치 탐지
        
3. k-평균을 사용할 때 적절한 클러스터 개수 선택 기법 2가지 
        
        1) 엘보 규칙 
        클러스터 개수를 x축, 이너셔(각 샘플과 인접한 센트로이드 사이의 평균 제곱 거리)를 y축으로 그리고 그래프에서 이너셔가 더는 빠르게 감소하지 않는 지점을 찾습니다. 
        일반적으로 이 지점이 최적의 클러스터 개수
        
        
![%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2023-05-03_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_7 42 01](https://github.com/alexturtleneckk/alexturtleneckk/assets/107594866/0ac79133-9e2c-4580-bd09-4d44ebbc50ff)
        
        
        2) 실루엣 점수를 그래프로 그리기
        
![%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2023-05-03_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_7 42 12](https://github.com/alexturtleneckk/alexturtleneckk/assets/107594866/2695ad00-442c-4b3d-a2fe-80df712c61d6)